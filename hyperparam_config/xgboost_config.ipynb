{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46ac7771",
      "metadata": {
        "id": "46ac7771"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from IPython.display import display\n",
        "\n",
        "import copy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f61bbac",
      "metadata": {
        "id": "8f61bbac"
      },
      "source": [
        "## TODO 00: Add GPU support to the script - modify wherever needed (including possibly other places marked with/without 'TODO' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c954237",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c954237",
        "outputId": "3f29ae85-ec85-416f-8333-56bcfed54e8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Use CPU/GPU\n",
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e346b07e",
      "metadata": {
        "id": "e346b07e"
      },
      "source": [
        "#### 1. Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49960ddc",
      "metadata": {
        "id": "49960ddc"
      },
      "outputs": [],
      "source": [
        "# TODO 01: Add the required (but missing here) configuration parameters and their values\n",
        "\n",
        "config = {\n",
        "    \"data_directory\": \"[INSERT DIRECTORY HERE]\",  # Path to your dataset directory\n",
        "    \"num_layers\": 4,\n",
        "    \"hidden_sizes\": [768, 512, 384, 256],\n",
        "    \"activation\": \"relu\",   # relu, leakyrelu, sigmoid\n",
        "    'leakyrelu_negative_slope': 0.02,\n",
        "    \"dropout_probs\": [0.35, 0.3, 0.25, 0.2],\n",
        "    \"normalization\": \"layernorm\",   # \"none\", \"batchnorm\", \"layernorm\", \"groupnorm\"\n",
        "    \"batch_size\": 128,\n",
        "    \"epochs\": 50,\n",
        "    \"learning_rate\": 3e-4,\n",
        "    \"weight_decay\":  2e-3,\n",
        "    \"optimizer\": \"adam\",    # adam or sgd\n",
        "    \"lr_scheduler\": 'OneCycle',   # None, 'OneCycle', 'ReduceOnPlateau'\n",
        "    \"OneCycle\": {'max_lr': 0.003},\n",
        "    \"patience\": 10,\n",
        "\n",
        "    #TODO 01: Missing Parameters\n",
        "    \"prototyping\": False,\n",
        "    \"prototyping_train_frac\": 0.2,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a81fbf0",
      "metadata": {
        "id": "8a81fbf0"
      },
      "source": [
        "#### 2. Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be61981d",
      "metadata": {
        "id": "be61981d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29a1ae41-deb8-4f28-982a-34847953c0d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 42.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Define transforms for CIFAR10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465),      # Normalize image channels using CIFAR-10 mean\n",
        "                         (0.2470, 0.2435, 0.2616))])    # Normalize RGB Standard Deviation\n",
        "\n",
        "# Load CIFAR10 dataset from the specified directory\n",
        "full_train = datasets.CIFAR10(config[\"data_directory\"], train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(config[\"data_directory\"], train=False, download=True, transform=transform)\n",
        "\n",
        "# Dataset parameters\n",
        "input_size = 32 * 32 * 3    # 32x32 images in RGB (3 channels)\n",
        "num_classes = 10            # 10 class outputs\n",
        "\n",
        "if config[\"prototyping\"]:\n",
        "    # work with a fraction of the full dataset for quicker prototyping (e.g. 20%); keep\n",
        "    # the train:frac ratio to 4:1\n",
        "    train_size_frac = config[\"prototyping_train_frac\"]\n",
        "\n",
        "    subset_len = int(train_size_frac * len(full_train))\n",
        "    remaining_len = len(full_train) - subset_len\n",
        "\n",
        "    # Split full_train --> prototyping subset (train_val) + remaining\n",
        "    train_val, _ = random_split(full_train, [subset_len, remaining_len])\n",
        "\n",
        "\n",
        "    train_size = int(0.8 * subset_len)    # Update Training to 80%\n",
        "    val_size = subset_len - train_size    # Update Val to %20\n",
        "\n",
        "\n",
        "else:\n",
        "    # Split train/val\n",
        "    train_size = int(0.8 * len(full_train))\n",
        "    val_size = len(full_train) - train_size\n",
        "    train_val = full_train\n",
        "\n",
        "train_dataset, val_dataset = random_split(train_val, [train_size, val_size])\n",
        "\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a15d6d1f",
      "metadata": {
        "id": "a15d6d1f"
      },
      "source": [
        "#### 3. Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3775fc2",
      "metadata": {
        "id": "f3775fc2"
      },
      "outputs": [],
      "source": [
        "# TODO 03: complete the following function\n",
        "# Hint: try to minimize code reuse and use a loop where it makes sense\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_sizes, num_classes, activation, dropout_probs, normalization, leakyrelu_negative_slope=0.01):\n",
        "        super(MLP, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        # Choose activation function\n",
        "        if activation == 'relu':\n",
        "            act_fn = nn.ReLU\n",
        "        elif activation == 'leakyrelu':\n",
        "            act_fn = lambda: nn.LeakyReLU(negative_slope=leakyrelu_negative_slope)\n",
        "        elif activation == 'sigmoid':\n",
        "            act_fn = nn.Sigmoid\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported activation: {activation}\")\n",
        "\n",
        "        # Build hidden layers\n",
        "        prev_size = input_size\n",
        "        for i, hidden_size in enumerate(hidden_sizes):\n",
        "            # Linear layer\n",
        "            self.layers.append(nn.Linear(prev_size, hidden_size))\n",
        "\n",
        "            # Normalization\n",
        "            if normalization == 'batchnorm':\n",
        "                self.layers.append(nn.BatchNorm1d(hidden_size))\n",
        "            elif normalization == 'layernorm':\n",
        "                self.layers.append(nn.LayerNorm(hidden_size))\n",
        "            elif normalization == 'groupnorm':\n",
        "                num_groups = min(32, hidden_size)  # Ensure groups divides hidden_size\n",
        "                self.layers.append(nn.GroupNorm(num_groups, hidden_size))\n",
        "\n",
        "            # Activation\n",
        "            self.layers.append(act_fn())\n",
        "\n",
        "            # Dropout\n",
        "            if i < len(dropout_probs):\n",
        "                self.layers.append(nn.Dropout(dropout_probs[i]))\n",
        "\n",
        "            prev_size = hidden_size\n",
        "\n",
        "        # Output layer\n",
        "        self.layers.append(nn.Linear(prev_size, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten the input\n",
        "        x = x.view(x.size(0), -1)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Instantiate model and move to device\n",
        "model = MLP(\n",
        "    input_size,\n",
        "    config[\"hidden_sizes\"],\n",
        "    num_classes,\n",
        "    config[\"activation\"],\n",
        "    config[\"dropout_probs\"],\n",
        "    config[\"normalization\"],\n",
        "    config['leakyrelu_negative_slope']\n",
        ").to(device)\n",
        "\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99ea35da",
      "metadata": {
        "id": "99ea35da"
      },
      "source": [
        "#### 4. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6cb57bd",
      "metadata": {
        "id": "c6cb57bd"
      },
      "outputs": [],
      "source": [
        "# TODO 04 (optional): Add code to implement the scheduler(s) logic\n",
        "\n",
        "def train_model(model, train_loader, val_loader, config):\n",
        "    # TODO 05: Add code to initialize the optimizer according to config[\"optimizer\"]\n",
        "    if config['optimizer'] == 'adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
        "    elif config['optimizer'] == 'sgd':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'], momentum=0.9)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported optimizer: {config['optimizer']}\")\n",
        "\n",
        "    # TODO 06: Define the loss function\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Initialize scheduler based on config\n",
        "    scheduler = None\n",
        "    if config['lr_scheduler'] == 'OneCycle':\n",
        "        scheduler = optim.lr_scheduler.OneCycleLR(\n",
        "            optimizer,\n",
        "            max_lr=config['OneCycle']['max_lr'],\n",
        "            steps_per_epoch=len(train_loader),\n",
        "            epochs=config['epochs']\n",
        "        )\n",
        "    elif config['lr_scheduler'] == 'ReduceOnPlateau':\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer,\n",
        "            mode='max',\n",
        "            factor=0.5,\n",
        "            patience=config['patience']//2,\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "    # Early stopping variables\n",
        "    best_val_acc = 0.0\n",
        "    patience_counter = 0\n",
        "    best_model_wts = None\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for X, y in train_loader:\n",
        "            # TODO 07: Add code to train the model (with GPU support)\n",
        "            X, y = X.to(device), y.to(device)              # Move data to device\n",
        "\n",
        "            optimizer.zero_grad()                          # Zero the gradients\n",
        "            outputs = model(X)                             # Forward pass\n",
        "            loss = criterion(outputs, y)                   # Compute loss\n",
        "            loss.backward()                                # Backward pass\n",
        "            optimizer.step()                               # Update weights\n",
        "\n",
        "            # Step scheduler if OneCycleLR\n",
        "            if config['lr_scheduler'] == 'OneCycle':\n",
        "                scheduler.step()\n",
        "\n",
        "            train_loss += loss.item() * X.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "        train_loss /= total\n",
        "        train_acc = correct / total\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        with torch.no_grad():\n",
        "            for X_val, y_val in val_loader:\n",
        "                # TODO 08: Add code to validate the model (with GPU support)\n",
        "                X_val, y_val = X_val.to(device), y_val.to(device)     # Move data to device\n",
        "\n",
        "                outputs_val = model(X_val)                             # Forward pass\n",
        "                loss_val = criterion(outputs_val, y_val)               # Compute loss\n",
        "\n",
        "                val_loss += loss_val.item() * X_val.size(0)\n",
        "                _, preds_val = torch.max(outputs_val, 1)\n",
        "                val_correct += (preds_val == y_val).sum().item()\n",
        "                val_total += y_val.size(0)\n",
        "\n",
        "        val_loss /= val_total\n",
        "        val_acc = val_correct / val_total\n",
        "\n",
        "        # Step scheduler if ReduceLROnPlateau\n",
        "        if config['lr_scheduler'] == 'ReduceOnPlateau':\n",
        "            scheduler.step(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{config['epochs']}: \"\n",
        "              f\"Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f}, \"\n",
        "              f\"Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}\")\n",
        "\n",
        "        # TODO 09: Add code to implement early stopping logic\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= config['patience']:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    # TODO 10: Add code to restore the best model weights\n",
        "    if best_model_wts is not None:\n",
        "        model.load_state_dict(best_model_wts)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f32f64e8",
      "metadata": {
        "id": "f32f64e8"
      },
      "outputs": [],
      "source": [
        "model = train_model(model, train_loader, val_loader, config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18f7bf08",
      "metadata": {
        "id": "18f7bf08"
      },
      "source": [
        "#### 5. Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5e49c61",
      "metadata": {
        "id": "c5e49c61"
      },
      "outputs": [],
      "source": [
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for X, y in loader:\n",
        "            # TODO 11: Add the missing lines to make testing work (with GPU support)\n",
        "            X, y = X.to(device), y.to(device)                                   # Move data to device\n",
        "            outputs = model(X)                                                  # Forward pass\n",
        "\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(y.cpu().numpy())\n",
        "    return correct / total, np.array(all_preds), np.array(all_labels)\n",
        "\n",
        "test_acc, preds, labels = evaluate(model, test_loader)\n",
        "print(f\"Overall Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Per-class accuracy\n",
        "for i in range(num_classes):\n",
        "    idx = labels == i\n",
        "    acc_i = (preds[idx] == labels[idx]).mean()\n",
        "    print(f\"Class {i}: {acc_i:.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(labels, preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=range(num_classes))\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39ff066b",
      "metadata": {
        "id": "39ff066b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e9237e6",
      "metadata": {
        "id": "4e9237e6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7a12d19",
      "metadata": {
        "id": "f7a12d19"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
